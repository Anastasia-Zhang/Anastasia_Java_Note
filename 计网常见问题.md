# 计算机网络常见问题

### TCP / UDP 的区别

#### 相同点
UDP协议和TCP协议都是传输层协议。

TCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个TCP连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。

UDP（User Data Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给IP层的数据报发送出去，但是不能保证它们能到达目的地。由于UDP在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。

#### 不同点

|      | TCP                                                | UDP                      |
| ---- | -------------------------------------------------- | ------------------------ |
| 传输 | 面向连接、传输字节流                               | 不建立连接、面向数据报   |
| 可靠 | 可靠（超时重发、确认机制、丢弃重复数据、流量控制） | 不可靠、只负责发送数据报 |
| 速度 | 慢                                                 | 快                       |

#### UDP

* **报头**

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\20180901091529706.png)

UDP数据报最大长度**64K**（包含UDP首部），如果数据长度超过64K就需要在应用层手动分包，UDP无法保证包序，需要在应用层进行编号。

* **特点**

  * **无连接**：知道对端的IP和端口号就直接进行传输, 不需要建立连接。
  * **不可靠**：没有确认机制, 没有重传机制; 如果因为网络故障该段无法发到对方, UDP协议层也不会给应用层返回任何错误信息。
  * **面向数据报**：不能够灵活的控制读写数据的次数和数量，应用层交给UDP多长的报文, UDP原样发送, 既不会拆分, 也不会合并。
  * 数据收不够灵活，但是能够明确区分两个数据包，避免粘包问题。
  * 传输速度比较快

* **协议：**

  NFS: 网络文件系统
  TFTP: 简单文件传输协议
  DHCP: 动态主机配置协议
  BOOTP: 启动协议(用于无盘设备启动)
  DNS: 域名解析协议

#### TCP

报头

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\20180901092556271.png)

* 源/目的端口号: 表示数据是从哪个进程来, 到哪个进程去;

* **32位序号/32位确认号: 不一定从0开始（作用：保证确认应答；保证数据按序到达；去重）**

* 4位TCP报头长度: 表示该TCP头部有多少个32位bit(有多少个4字节); 所以TCP报头最大长度是15 * 4 = 60 字

* **6位标志位:**

  URG: 紧急指针是否有效

  **ACK: 确认号是否有效**

  PSH: 提示接收端应用程序立刻从TCP缓冲区把数据读走

  RST: 对方要求重新建立连接; 我们把携带RST标识的称为复位报文段

  **SYN: 请求建立连接; 我们把携带SYN标识的称为同步报文段**

  **FIN: 通知对方, 本端要关闭了, 我们称携带FIN标识的为结束报文**

* **16位窗口大小: 接收缓冲区剩余的空间大小** 
* **16位校验和**: 发送端填充, CRC校验. 接收端校验不通过, 则认为数据有问题. 此处的检验和不光包含TCP 首部,
* 也包含TCP数据部分. 
* 16位紧急指针: 标识哪部分数据是紧急数据; 



#### TCP三次握手过程

1. 主机A通过向主机B 发送一个含有同步序列号标志位的数据段（SYN）给主机B ，向主机B 请求建立连接，通过这个数据段，主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为起始数据段来回应我
2. 主机B 收到主机A的请求后，用一个带有确认应答(ACK)和同步序列号(SYN)标志位的数据段响应主机A，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我。
3. 主机A收到这个数据段后，再发送一个确认应答，确认已收到主机B 的数据段：“我已收到回复,我现在要开始传输实际数据了”。
   这样3次握手就完成了，主机A和主机B 就可以传输数据了。

#### 为啥三次握手

是为了确认双方接收和发送都正常

1. 第一次握手，A发送的网络包，B收到了。主机B确定 A（对方）发送正常，B（我方）接收正常
2. 第二次握手，B发送的网络包，A收到了。主机A确定 B （对方）发送正常，接收正常 ，A（我方）接收正常，发送正常。
3. 第三次握手，A发送的网络包，B收到了。主机B确定 A（对方）接收正常，B（我方）发送正常

#### TCP四次挥手过程

1. 当主机A完成数据传输后，将控制位FIN置1，提出停止TCP连接的请求。
2. 主机B收到FIN后对其作出响应，确认这一方向上的TCP连接将关闭，将ACK置1，进入关闭等待。（主动关闭方无数据发送，被动关闭方发送数据，主动方仍要接收）
3. B端数据传输完了，由B 端再提出反方向的关闭请求，将FIN置1。
4. 主机A对主机B的请求进行确认
5. 主动关闭连接的一方要处于**TIME_ WAIT状态**,等待两个MSL(最大报文生存周期)的时间后才能回到CLOSED状态。

**为啥有 TIME_WAIT 状态**
保证最后一个报文可靠到达(假设最后⼀一个ACK丢失, 那么服务器会再重发一个 FIN.。这时虽然客户端的进程不在了, 但是TCP连接还在, 仍然可以重发LAST_ACK)。

<img src="E:\研究生学习\Work\技术笔记\计网常见问题.assets\aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8zLzI4LzE2OWMzOWNjMThlNzU5MmE.jfif" alt="img"  />

#### TCP的可靠传输机制

序列号 确认应答 超时重传 拥塞控制

**确认应答机制&序列号**

TCP将每个字节的数据都进行了编号，即为序列号。
**每一个ACK都带有对应的确认序列号，意思是告诉发送者，我已经收到了哪些数据;；下一次你从哪里开始发。**

**超时重传&序列号**

A 给 B 发送数据，A 没有收到 B  的确认

* A 发给 B 的数据丢失：主机A发送数据给B之后, 可能因为网络拥堵等原因, 数据无法到达主机B;  超时重传
* B 发给 A 的确认丢失：可能 B 收到 A 的数据，只是 B 发送的 ACK 丢失了；A 超时重传，B 收到之后丢弃重复的包（可以利用序列号）

#### **拥塞控制**

每次发送数据包的时候, 将**拥塞窗口**和**接收端主机反馈的窗口**大小做比较, 取较小的值作为实际发送的窗口。
拥塞控制, 归根结底是TCP协议想尽可能快的把数据传输给对方, 但是又要避免给网络造成太大压力的折中方案。

TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

为了便于讨论，做如下假设：

- 接收方有足够大的接收缓存，因此不会发生流量控制；
- 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\910f613f-514f-4534-87dd-9b4699d59d31.png)





* **慢开始**：指数增加，令 cwnd = 1，发送方只能发送 1 个报文段；**当收到确认后，将 cwnd 加倍**，因此之后发送方能够发送的报文段数量为：2、4、8 ...

* **拥塞避免：**注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高，因此有拥塞避免阶段。**设置慢开始门限 ssthresh，如果拥塞窗口达到慢开始门限的值。 进入拥塞避免阶段。设置一个每个轮次只将 cwnd 加 1。**
* **如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。**

* **在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段**
* 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，**令 ssthresh = cwnd / 2** ，**cwnd = ssthresh，注意到此时直接进入拥塞避免。**

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。慢开始是指数增加；快恢复是加法增加



提高传输效率：滑动窗口、流量控制、延迟应答、捎带应答

**滑动窗口机制**

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收

1. 窗口大小指的是无需等待确认应答而可以继续发送数据的最大值.
2. **发送窗口内字段的时候, 不需要等待任何ACK, 直接发送;**
3. **收到第一个ACK后, 滑动窗口向后移动, 继续发送下一个窗口字段的数据; 依次类推**;
4. 操作系统内核为了维护这个滑动窗口, 需要开辟**发送缓冲区来记录当前还有哪些数据没有应答**; 接收窗口只会对窗口内最后一个按序到达的字节进行确认；只有确认应答过的数据, 才能从缓冲区删掉;
5. 窗口越大, 则网络的吞吐率就越高

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg)

**流量控制**
接收端处理数据的速度是有限的. 如果发送端发的太快, 导致接收端来不及确认, 这个时候如果发送端继续发送, 就会造成丢包, 继而引起丢包重传等等一系列连锁反应。

**流量控制是为了控制发送方发送速率，保证接收方来得及接收。**

**接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率**。将窗口字段设置为 0，则发送方不能发送数据。

1.接收端将自己可以接收的缓冲区大小放入TCP首部中的 "窗口大小" 字段, 通过ACK端通知发送端来控制发送端窗口的大小; 
3.接收端一旦发现自己的缓冲区快满了, 就会将窗口大小设置成一个更小的值通知给发送端; 
4.发送端接受到这个窗口之后, 就会减慢自己的发送速度; 
5.如果接收端缓冲区满了, 就会将窗口置为0; 这时发送⽅方不再发送数据, 但是需要定期发送一个窗口

**延迟应答**
如果接收数据的主机立刻返回ACK应答, 这时候返回的窗口可能比较小.
窗口越大, 网络吞吐量就越大, 传输效率就越高. 我们的目标是在保证网络不拥塞的情况下尽量提高传输效率;

**捎带应答**
在延迟应答的基础上, 我们发现, 很多情况下, 客户端服务器在应用层也是 “一发一收” 的.
意味着客户端给服务器说了 “How are you”, 服务器也会给客户端回一个 “Fine, thank you”; 那么这个时候ACK就可以搭顺风车, 和服务器回应的 “Fine, thank you” 一起回给客户端。

**面向字节流：**

创建一个TCP的socket, 同时在内核中创建一个发送缓冲区和一个接收缓冲区；
另一方面, TCP的一个连接, 既有发送缓冲区, 也有接收缓冲区, **那么对于这一个连接, 既可以读数据, 也可以写数据. 这个概念叫做 全双工 。**

调用write时, 数据会先写入发送缓冲区中;
如果发送的字节数太长, 会被拆分成多个TCP的数据包发出; 如果发送的字节数太短, 就会先在缓冲区里等待, 等到缓冲区长度差不多了, 或者其他合适的时机发送出去;
接收数据的时候, 数据也是从网卡驱动程序到达内核的接收缓冲区;
然后应用程序可以调用read从接收缓冲区拿数据;

#### TCP粘包问题

首先要明确, 粘包问题中的 “包” , 是指的**应用层的数据包**；
在TCP的协议头中, 没有如同UDP一样的 “报文长度” 这样的字段, 但是有一个序号这样的字段；
站在传输层的角度, TCP是一个一个报文过来的，按照序号排好序放在缓冲区中；
站在应用层的角度, 看到的只是一串连续的字节数据. 那么应用程序看到了这么一连串的字节数据, **就不知道从哪个部分开始到哪个部分是一个完整的应用层数据包。**
那么如何避免粘包问题呢?
**归根结底就是一句话, 明确两个包之间的边界.**

1.对于定长的包, 保证每次都按固定大小读取即可;
2.对于变长的包, 可以在报头的位置, 约定一个包总长度的字段, 从而就知道了包的结束位置;
3.对于变长的包, 还可以在包和包之间使用明确的分隔符。
4.TLV格式的数据传输

**TCP异常情况**

进程终止: 进程终止会释放文件描述符, 仍然可以发送FIN. 和正常关闭没有什么区别.
机器重启: 和进程终止的情况相同
机器掉电/网线断开: 接收端认为连接还在, 一旦接收端有写入操作, 接收端发现连接已经不在了, 就会进行 reset. 即使没有写入操作, TCP自己也内置了一个保活定时器, 会定期询问对方方是否还在. 如果对方不在, 也会把连接释放



## I/O模型

### 系统I/O

**系统I/O产生的阶段**

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640-1583293508162.png)

系统I/O的发生是内核将磁盘数据拷贝到用户空间的这个过程，每次I/O都要经过两个阶段：

- 第一步：将数据从磁盘文件先加载至内核内存空间（缓冲区），等待数据准备完成，时间较长
- 第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短

### I/O模型的区分

- 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
- 异步 I/O：第二阶段应用进程不会阻塞。（可以把第二阶段放在回调函数去执行）

- **同步:**同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行
- **异步:**异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。

> 同步/异步：关注的是消息通信机制

阻塞 非阻塞看阻塞的是否是第一步

- **阻塞:**指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起
- **非阻塞:**指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成，最终的调用结果返回之前，调用者不会被挂起

> 阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态

### I/O模型类别

在同步/异步，阻塞/非阻塞 的区分下，I/O模式工作模式又分为5种，分别为：

阻塞I/O模型，非阻塞I/O模型，I/O复用模型，信号驱动I/O模型，异步I/O模型

#### 阻塞I/O模型

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640-1583293508106.png)

- 同步阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞
- 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作
- 用户需要等待read将数据读取到buffer后，才继续处理接收的数据**。整个IO请求的过程中，用户线程是被阻塞的**，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够

#### 非阻塞I/O模型

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640-1583293508141.png)

- 用户线程发起IO请求时立即返回。若有数据则返回数据，若无数据的话则返会错误码。如果未读取到任何数据，**用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行**。即 “轮询”机制
- 整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源
- 是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性

#### I/O多路复用

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640-1583293508145.png)

- 如果说数据就绪了系统能通知程序，而不是让应用程序轮询检测数据的就绪状态，岂不是就解决了非阻塞模型中的效率问题？是的，多路复用模型就是利用了系统的通知功能。常用的I/O多路复用有select和epoll。线程阻塞会阻塞在 select 和 poll 上，并非阻塞在真正的 I/O操作上。

- 好处：使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。

  **它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。**

  如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

- **select** ：**先说多路复用中的**selector。selector可以同时监听多个fd（File Descriptor - 文件描述符，比如文件系统的文件，socket都可以看做是文件，可以用fd表示）的某个就绪事件。以socket为例，**selector可以监听多个socket的数据就绪状态。程序调用select方法，当所有监听的socket数据都没有就绪的时候，select会阻塞在这里，当被监听的socket中有数据就绪的了，select方法就返回了，应用程序需要遍历所有的socket去尝试读取数据。**这种模型使得用户程序可以用一个专门的线程负责监听所有的socket的状态，避免了阻塞模型中为每个socket单独创建一个线程的情形。

- 但是select的问题也很明显，就是**系统不能通知到具体是哪一个socket的数据就绪了，程序需要遍历整个监听列表中所有的socket**，会浪费CPU。并且Select监听的fd的个数也是有限制的，Linux上是1024。Java的NIO就使用了selector模型。

- **epoll：** 那对于上面的例子，系统可不可以通知程序具体是哪些socket的数据就绪了？Linux上的epoll可以做到。epoll提供了三个API，epoll_create, epoll_ctl, epoll_wait，分别可以创建epoll数据结构，注册监听fd的事件（比如注册监听socket的数据接收），和等待事件的发生。调用epoll_wait方法时，如果监听的事件没有发生，则会阻塞。继续以server端socket为例，应用程序按照类似selector的方式使用epoll，不**同的是当某些socket数据就绪的时候，可以获取就绪的socket列表，而不需要遍历和检测所有的socket**。epoll内部以一种非常高效的方式提供这个就绪的fd列表，**并且没有监听数目的限制**。这使得Linux系统可以以更简单高效的方式支持更多的连接。

- IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因为它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO模型，而非真正的异步IO

- IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，就通知该进程

**I/O多路复用适用如下场合**

- 当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用
- 当一个客户端同时处理多个套接字时，此情况可能的但很少出现
- 当一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用
- 当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用
- 当一个服务器要处理多个服务或多个协议，一般要使用I/O复用

#### 信号驱动I/O模型

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640.png)

信号驱动IO：signal-driven I/O

- 用户进程可以通过sigaction系统调用注册一个信号处理程序，然后主程序可以继续向下执行，当有IO操作准备就绪时，由内核通知触发一个SIGIO信号处理程序执行，然后将用户进程所需要的数据从内核空间拷贝到用户空间
- 此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知
- 该模型并不常用

#### 异步I/O模型

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640-1583293508102.png)

- 异步IO与信号驱动IO最主要的区别是**信号驱动IO是由内核通知何时可以进行IO操作，而异步IO则是由内核告诉我们IO操作何时完成了。**
- 具体来说就是，信号驱动IO当内核通知触发信号处理程序时，信号处理程序还需要阻塞在从内核空间缓冲区拷贝数据到用户空间缓冲区这个阶段，而异步IO直接是在第二个阶段完成后内核直接通知可以进行后续操作了
- 异步模型还可以提供一个回调方法，I/O方法调用会立刻返回，等到数据就绪时回调方法会执行。这个看上去很好用，把所有的处理都推给了系统，用户只需要关心回调方法中的数据处理就行了，但是在高并发情况下，处理好系统I/O程序和用户程序之间的CPU竞争比较困难。
- 相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用IO多路复用模型+多线程任务处理的架构基本可以满足需求。况且目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中）

### 五种I/O模型对比

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\640.jfif)

### I/O模型的具体实现

常用的主要实现方式有以下几种：

- Select：Linux实现对应，I/O复用模型，BSD4.2最早实现
- Poll：Linux实现，对应I/O复用模型，System V unix最早实现
- Epoll：Linux实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性

select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。




#### select

Select:POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理

```c
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```



select函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。


**缺点**

- **单个进程可监视的fd数量被限制，即能监听端口的数量有限，默认1024**
  cat /proc/sys/fs/file-max
  
- 每次调用select都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大

- **对socket是线性扫描，即采用轮询的方法**，效率较低；每次调用select都需要在内核遍历传递进来的所有fd，查看有没有就绪的fd，这个开销在fd很多时也很大，效率随FD数目增加而线性下降

  

#### poll

```C
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
```

不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。

```c
struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

* **其没有最大连接数的限制**。

* 每次调用select都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
* 每次调用select都需要在内核遍历传递进来的所有fd，查看有没有就绪的fd，这个开销在fd很多时也很大，效率随FD数目增加而线性下降
* **poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd**

> 边缘触发：只通知一次; 水平触发：重复通知



#### select 和 poll 的比较

**功能**

select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。

- select 会修改描述符，而 poll 不会；
- **select 的描述符类型使用数组实现**，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 **poll 没有描述符数量的限制**；
- poll 提供了更多的事件类型（水平触发），并且对描述符的重复利用上比 select 高。
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。

**速度**

select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。

**可移植性**

几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。



#### epoll

```c
int epoll_create(int size)；
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个事件表（链表）中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。

在Linux 2.6内核中提出的select和poll的增强版本支持水平触发LT和边缘触发ET，最大的特点在于**边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次**

1. `int epoll_create(int size);`

   创建一个epoll的句柄，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。
   当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

2. `int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；`
   函数是对指定描述符fd执行op操作。

   1. epfd：是epoll_create()的返回值。
   2. op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除
   3. EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
   4. fd：是需要监听的fd（文件描述符）
   5. epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：

   ```c
   struct epoll_event {
     __uint32_t events;  /* Epoll events */
     epoll_data_t data;  /* User data variable */
   };
   
   //events可以是以下几个宏的集合：
   EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
   EPOLLOUT：表示对应的文件描述符可以写；
   EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
   EPOLLERR：表示对应的文件描述符发生错误；
   EPOLLHUP：表示对应的文件描述符被挂断；
   EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
   EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
   ```

3. `int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);`
   等待epfd上的io事件，最多返回maxevents个事件。
   参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将永久阻塞直到有监听的io事件发生）。该函数返回需要处理的事件数目，如返回0表示已超时。

epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：

* LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。

* ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

**优点**

- **没有最大并发连接的限制**：能打开的FD的上限远大于1024(1G的内存能监听约10万个端口)
- select和poll每次调用都需要把所有要监听的fd重新拷贝到内核空间；epoll只在调用epoll_ctl时拷贝一次要监听的fd，调用epoll_wait时不需要每次把所有要监听的fd重复拷贝到内核空间。
- **效率提升：非轮询的方式**，I/O效率不会随着FD数目的增加而效率下降；传统的select/poll 的弱点就是当有一个很大的药监听的文件描述符，只有少量活跃的fd，全部扫描集合，效率就会下降。epoll不存在这个问题，它只会对”活跃”的socket进行操作。这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket才会主动的去调用callback函数，其他idle状态socket则不会。
- **内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递；即epoll使用mmap减少复制开销**

### Select、Poll与Epoll区别

|              | select                                          | poll                                  | epoll                                                        |
| ------------ | ----------------------------------------------- | ------------------------------------- | ------------------------------------------------------------ |
| 最大支持链接 | 1024（x86） or 2048（x64）                      | 无上限                                | 无上限                                                       |
| IO效率       | 每次调用进行线性遍历全部的fd 时间复杂度为O（N） | 线性遍历全部的  fd 时间复杂度为O（N） | 使用“事件”通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面，这样epoll_wait返回的时候我们就拿到了就绪的fd。时间发复杂度O（1） |
| fd拷贝       | 每次select都拷贝                                | 每次poll都拷贝                        | 调用epoll_ctl时拷贝进内核并由内核保存，之后每次epoll_wait不拷贝 |




### I/O 复用模型的应用场景

#### 1. select 应用场景

select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，**因此 select 更加适用于实时性要求比较高的场景**，比如核反应堆的控制。

select 可移植性更好，几乎被所有主流平台所支持。

#### 2. poll 应用场景

**poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高**，应该使用 poll 而不是 select。

#### 3. epoll 应用场景

只需要运行在 Linux 平台上，**有大量的描述符需要同时轮询**，并且这些连接最好是长连接。

需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。

需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。

## AIO NIO BIO

IO：阻塞IO

**BIO**：同步阻塞IO。服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器需要启动一个线程进行处理，如果这个链接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。

**NIO**：同步非阻塞IO，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有IO请求时才启动一个线程进行处理。用户进程也需要时不时的询问IO操作是否就绪，这需要用户进行不停的去询问。NIO的包括三个核心概念:缓冲区(Buffer)、通道(Channel)、选择器(Selector)。

**AIO**：Asynchronous IO，异步非阻塞AIO。最大的特性时具有异步能力，这种能力对socket与文件I/O都起作用。AIO其实是一种在读写操作结束之前允许进行其他操作的I/O处理。

### 应用场景

BIO：适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4之前的唯一选择， 但是程序简单直观容易理解。

NIO：适用于连接数目多且连接比较短（轻操作）的架构，比如聊推荐服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。

AIO：适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK1.7开始支持。

NIO能解决什么问题？

NIO采用的是一种多路复用的机制，利用单线程轮询事件，高效定位就绪的Channel来决定做什么，只是Select阶段是阻塞式的，能有效避免大量连接数时，频繁线程的切换带来的性能或各种问题。

![在这里插入图片描述](E:\研究生学习\Work\技术笔记\计网常见问题.assets\20190903225111705.png)


首先，Requester方通过Selector.open()创建了一个Selector准备好了调度角色。

创建了SocketChannel(ServerSocketChannel) 并注册到Selector中，通过设置key（SelectionKey）告诉调度者所应该关注的连接请求。

阻塞，Selector阻塞在select操作中，如果发现有Channel发生连接请求，就会唤醒处理请求。



## POST 和 GET

| 浏览器端            | GET                                                          | POST                                                         |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 作用                | GET主要是请求的资源，如请求http页面，查询某个数据            | 用来向目的服务器发出请求，要求它接收被附在请求后的实体，如更新数据、提交表单 |
| 幂等性              | 反复读取对访问的数据没有副作用，幂等性；可以做缓存           | 不是幂等性；无法做缓存                                       |
| URL/ 携带数据的格式 | **请的求的数据会附加在URL之后**，以?分隔URL和传输数据，多个参数用&连接。URL编码格式采用的是ASCII编码 | **表单的数据被浏览器用编码到HTTP请求的body里**。浏览器发出的POST请求的body主要有有两种格式，一种是`application/x-www-form-urlencoded`用来传输简单的数据，大概就是"key1=value1&key2=value2"这样的格式。另外一种是传文件，会采用`multipart/form-data`格式。采用后者是因为application/x-www-form-urlencoded的编码方式对于文件这种二进制的数据非常低效 |
| 数据的大小          | 因为URL的长度限制，GET方式传输的数据大小有所限制，传送的数据量不超过2KB | POST方式传送的数据量比较大，一般被默认为没有限制，但是根据IIS的配置，传输量也是不同的。 |
| 安全性              | GET方式传输的参数安全性低，因为传输的数据会显示在请求的URL中 | POST方式传输的数据安全性较高，因为数据传输不是明显显示的     |

### 接口中的区别

REST充分运用GET、POST、PUT和DELETE，约定了这4个接口分别获取、创建、替换和删除“资源”，REST最佳实践还推荐在请求体使用json格式。这样仅仅通过看HTTP的method就可以明白接口是什么意思，并且解析格式也得到了统一。

> json相对于x-www-form-urlencoded的优势在于1）可以有嵌套结构；以及 2）可以支持更丰富的数据类型。通过一些框架，json可以直接被服务器代码映射为业务实体。用起来十分方便。但是如果是写一个接口支持上传文件，那么还是multipart/form-data格式更合适。

REST中GET和POST不是随便用的。在REST中, 【GET】 + 【资源定位符】被专用于获取资源或者资源列表，比如：

```text
GET http://foo.com/books          获取书籍列表
GET http://foo.com/books/:bookId  根据bookId获取一本具体的书
```

REST 【POST】+ 【资源定位符】则用于“创建一个资源”，比如：

```text
POST http://foo.com/books
{
  "title": "大宽宽的碎碎念",
  "author": "大宽宽",
  ...
}
```

## HTTP / HTTPS

### **一、HTTP和HTTPS的基本概念**

**HTTP**：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。

**HTTPS**：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。

**HTTPS协议的主要作用可以分为两种**：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

### 二 **、**HTTP和HTTPS的主要特点和工作流程

#### **HTTP特点**

1.支持客户/服务器模式。（C/S模式）

2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。

3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。

4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。

5.无状态：HTTP协议是**无状态协议**。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快

### HTTP格式

#### request 首部

```
GET http://www.new1.uestc.edu.cn/public/image/header_menu.png HTTP/1.1
Host: www.new1.uestc.edu.cn
Proxy-Connection: keep-alive
User-agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36
Accept: image/webp,image/apng,image/*,*/*;q=0.8
Referer: http://www.new1.uestc.edu.cn/public/UestcNews/dist/c5b9577e5d76a65d03b688041d94011f.css
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9
Cookie: ...
```

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\HTTP_RequestMessageExample.png)

| 首部字段名      | 说明                     |
| --------------- | ------------------------ |
| Accept          | 用户代理可处理的媒体类型 |
| Accept-Charset  | 优先的字符集             |
| Accept-Encoding | 优先的内容编码           |
| Accept-Language | 优先的语言（自然语言）   |
| Authorization   | Web 认证信息             |
| User-Agent      | HTTP 客户端程序的信息    |
| From            | 用户的电子邮箱地址       |
| Host            | 请求资源所在服务器       |

#### response

```
HTTP/1.1 200 OK
Server: nginx
Date: Tue, 19 Jun 2018 05:16:27 GMT
Content-Type: image/png
Content-Length: 246
Last-Modified: Wed, 08 Apr 2015 18:39:02 GMT
Connection: close
ETag: "552575c6-f6"
Expires: Thu, 19 Jul 2018 05:16:27 GMT
Cache-Control: max-age=2592000
Accept-Ranges: bytes
Proxy-Connection: keep-alive
```

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\HTTP_ResponseMessageExample.png)

| 首部字段名         | 说明                         |
| ------------------ | ---------------------------- |
| Accept-Ranges      | 是否接受字节范围请求         |
| Age                | 推算资源创建经过时间         |
| ETag               | 资源的匹配信息               |
| Location           | 令客户端重定向至指定 URI     |
| Proxy-Authenticate | 代理服务器对客户端的认证信息 |
| Retry-After        | 对再次发起请求的时机要求     |
| Server             | HTTP 服务器的安装信息        |
| Vary               | 代理服务器缓存的管理信息     |
| WWW-Authenticate   | 服务器对客户端的认证信息     |

实体首部字段

| 首部字段名       | 说明                   |
| ---------------- | ---------------------- |
| Allow            | 资源可支持的 HTTP 方法 |
| Content-Encoding | 实体主体适用的编码方式 |
| Content-Language | 实体主体的自然语言     |
| Content-Length   | 实体主体的大小         |
| Content-Location | 替代对应资源的 URI     |
| Content-MD5      | 实体主体的报文摘要     |
| Content-Range    | 实体主体的位置范围     |
| Content-Type     | 实体主体的媒体类型     |
| Expires          | 实体主体过期的日期时间 |
| Last-Modified    | 资源的最后修改日期时间 |

#### **HTTP工作流程**

第一步：建立TCP/IP连接，客户端与服务器通过Socket三次握手进行连接

第二步：客户端向服务端发起HTTP请求（例如：POST/login.html http/1.1）

第三步：客户端发送请求头信息，请求内容，最后会发送一空白行，标示客户端请求完毕

第四步：服务器做出应答，表示对于客户端请求的应答，例如：HTTP/1.1 200 OK

第五步：服务器向客户端发送应答头信息

第六步：服务器向客户端发送请求头信息后，也会发送一空白行，标示应答头信息发送完毕，接着就以Content-type要求的数据格式发送数据给客户端

第七步：服务端关闭TCP连接，如果服务器或者客户端增Connection:keep-alive就表示客户端与服务器端继续保存连接，在下次请求时可以继续使用这次的连接

#### **HTTPS特点**

HTTPS是HTTP协议的修改，它加密数据并确保其机密性。其配置可保护用户在与网站交互时免于窃取个人信息和计费数据。

1、优点

相比于http，https可以提供更加优质保密的信息，保证了用户数据的安全性，此外https同时也一定程度上保护了服务端，使用恶意攻击和伪装数据的成本大大提高。

2、缺点

缺点也同样很明显，第一https的技术门槛较高，多数个人或者私人网站难以支撑，CA机构颁发的证书都是需要年费的，此外对接Https协议也需要额外的技术支持；其二，目前来说大多数网站并不关心数据的安全性和保密性，其https最大的优点对它来说并不适用；其三，https加重了服务端的负担，相比于http其需要更多的资源来支撑，同时也降低了用户的访问速度；第四，目前来说Http网站仍然大规模使用，在浏览器侧也没有特别大的差别，很多用户不关心的话根本不感知。

#### **HTTPS工作流程**

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\023b5bb5c9ea15ce26b853cd9cdca2f73887b284.jpeg)

第一步：客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。

第二步：Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。

第三步：客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。

第四步：客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。

第五步Session：Web服务器利用自己的私钥解密出会话密钥。

第六步：Web服务器利用会话密钥加密与客户端之间的通信。

### 三、二者前区别

1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

2、**http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议**。

3、http和https使用的是完全不同的连接方式，用的端口也不一样，**前者是80，后者是443**。

4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。



## Cookie 和 Session

都是用来存储状态信息的。 

1. session 在服务器端，cookie 在客户端（浏览器）
2. session 默认被存在在服务器的一个文件里（不是内存）
3. session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id）
4. session 可以放在 文件、数据库（session持久化）、或内存中都可以。
5. 用户验证这种场合一般会用 session
   - 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
   - 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
   - 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
   - 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。
6. Cookie 只能存储 ASCII 码字符串， Session 则可以存储任何类型的数据。
7. Cookie 浏览器不安全，可以对 Cookie 进行加密，在服务器端进行解密

## Token

传统 session 和 cookie 认证

* cookie有效范围：当前域名下有效。所以**session这种会话存储方式方式只适用于客户端代码和服务端代码运行在同一台服务器上**（前后端项目协议、域名、端口号都一致，即在一个项目下）
* 而 Token 适合前后端分离，域名端口号不一致
* Cookie 安全性问题
* Session 扩展性问题：持久化，redis内存

#### token认证机制

token与session的不同主要在①认证成功后，会对当前用户数据进行加密，生成一个加密字符串token，返还给客户端（服务器端并不进行保存）

②浏览器会将接收到的token值存储在Local Storage中，（通过js代码写入Local Storage，通过js获取，并不会像cookie一样自动携带）

③再次访问时服务器端对token值的处理：服务器对浏览器传来的token值进行解密，解密完成后进行用户数据的查询，如果查询成功，则通过认证，实现状态保持，所以，即时有了多台服务器，服务器也只是做了token的解密和用户数据的查询，它不需要在服务端去保留用户的认证信息或者会话信息，这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利，解决了session扩展性的弊端。


![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\20181126161842605.png)

## 递归查询与迭代查询

 一、主机向本地域名服务器的查询一般都是采用递归查询。

​    所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。

二、本地域名服务器向根域名服务器的查询的迭代查询。

​    迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。

​    然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。

​    顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。

​    最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机

## Ping的协议

ICMP 是 TCP/IP 模型中网络层的重要成员，与 IP 协议、ARP 协议、RARP 协议及 IGMP 协议共同构成 TCP/IP 模型中的网络层。

**我们用的ping操作中就包括了相应请求（类型字段值为8）和应答（类型字段值为0）ICMP报文。**测试网络的可达性。

**过程：**
一台主机向一个节点发送一个类型字段值为8的**ICMP报文**，如果途中没有异常（如果没有被路由丢弃，目标不回应ICMP或者传输失败），则目标返回类型字段值为0的ICMP报文，说明这台主机存在。

### ICMP协议

* ICMP协议是一个网络层协议。
* 一个新搭建好的网络，往往需要先进行一个简单的测试，来验证网络是否畅通；**但是IP协议并不提供可靠传输。如果丢包了，IP协议并不能通知传输层是否丢包以及丢包的原因。**
* 所以我们就需要一种协议来完成这样的功能–ICMP协议。

ICMP协议的功能

#### ICMP协议的功能主要有：

1. 确认IP包是否成功到达目标地址
2. 通知在发送过程中IP包被丢弃的原因
![这里写图片描述](E:\研究生学习\Work\技术笔记\计网常见问题.assets\20180530175416942.png)


### 目标不可达，源抑制和超时报文

这三种报文的格式是一样的。
（1）**目标不可到达报文（类型值为3）在路由器或者主机不能传递数据时使用。**
例如：我们要连接对方一个不存在的系统端口（端口号小于1024）时，将返回类型字段值3、代码字段值为3的ICMP报文。
  **常见的不可到达类型还有网络不可到达（代码字段值为0）、主机不可达到（代码字段值为1）、协议不可到达（代码字段值为2）等等。**
（2）**源抑制报文（类型字段值为4，代码字段值为0）则充当一个控制流量的角色，通知主机减少数据报流量。**由于ICMP没有回复传输的报文，所以只要停止该报文，主机就会逐渐恢复传输速率。
（3）无连接方式网络的问题就是数据报会丢失，或者长时间在网络游荡而找不到目标，或者拥塞导致主机在规定的时间内无法重组数据报分段，**这时就要触发ICMP超时报文的产生。**
超时报文（类型字段值为11）的代码域有两种取值：代码字段值为0表示传输超时，代码字段值为1表示分段重组超时。


Ping功能应用：

1、 使用ipconfig /all观察本地网络设置是否正确；

2、 Ping127.0.0.1，127.0.0.1回送地址Ping回送地址是为了检查本地的TCP/IP协议有没有设置好；

3、Ping本机IP地址，这样是为了检查本机的IP地址是否设置有误；

4、Ping本网网关或本网IP地址，这样的是为了检查硬件设备是否有问题，也可以检查本机与本地网络连接是否正常；（在非局域网中这一步骤可以忽略）

5、Ping本地DNS地址，这样做是为了检查本地DNS服务器是否工作正常。

6、Ping远程IP地址，这主要是检查本网或本机与外部的连接是否正常。

## DNS解析的过程

（1）检查浏览器缓存、检查**本地hosts文件**是否有这个网址的映射，如果有，就调用这个IP地址映射，解析完成。

（2）如果没有，则查找本地**DNS解析器缓存**是否有这个网址的映射，如果有，返回映射，解析完成。

（3）如果没有，则查找填写或分配的首选DNS服务器，称为**本地DNS服务器**。服务器接收到查询时：

* **如果要查询的域名包含在本地配置区域资源中**，返回解析结果，查询结束，**此解析具有权威性**。

* **如果要查询的域名不由本地DNS服务器区域解析**，但服务器缓存了此网址的映射关系，返回解析结果，查询结束，此解析不具有权威性。

（4）如果本地DNS服务器也失效：

**如果未采用转发模式（迭代），**本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后，会判断这个域名（如.com）是谁来授权管理，并返回一个负责该顶级域名服务器的IP，本地DNS服务器收到顶级域名服务器IP信息后，继续向该顶级域名服务器IP发送请求，该服务器如果无法解析，则会找到负责这个域名的下一级DNS服务器（如[http://baidu.com](http://baidu.com/)）的IP给本地DNS服务器，循环往复直至查询到映射，将解析结果返回本地DNS服务器，再由本地DNS服务器返回解析结果，查询完成。

**如果采用转发模式（递归）**，则此DNS服务器就会把请求转发至上一级DNS服务器，如果上一级DNS服务器不能解析，则继续向上请求。最终将解析结果依次返回本地DNS服务器，本地DNS服务器再返回给客户机，查询完成。

### 反向代理

（1）反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。

（2）反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。

（3）反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。

（4）其缺点主要表现在以下两个方面

反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。

针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。

一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search等。



## 一台服务器所受的最大连接数

在性能测试过程中，经常会接触到链接数相关的问题，有一个问题曾经困扰我好长时间，那就是一台服务器最多能支持多少链接数呢？

有的朋友可能会说是65535，因为操作系统有65535个端口，那么这个答案准确吗？

首先先了解下如何标识一个链接（记住下面的概念，文章后面要用到），操作系统是通过一个四元组来标识一个TCP链接：

**{本地ip，本地port，远程ip，远程port}**

这四个要素唯一确定一个TCP链接，任意一个要素不相同，就认为是一个不同的链接。

在Linux系统中，一切皆文件，每一个TCP链接都要占用一个文件句柄，系统允许创建的链接数取决于句柄数的上限。超过这个值再创建链接就会报这样的错误：

“Can't open so many files"

通过命令ulimit -n可以查看当前系统允许打开文件数量的上限，在Linux中这个值默认是1024，也就是说默认情况下，只能创建1024个链接。同时这个值也是可以修改的，通过修改/etc/security/limits.conf文件，可以把这个值改大，一般服务器都会改的很大，比如我们的服务器上一般设置为1000000。

那这么说是不是就意味着只要我改的很大，链接数可以无限大了？

其实也并不是这样，创建链接的时候，一般分为两个端，即链接的发起端和链接接收端。比如我们现在使用Jmeter进行压测，被测系统部署在Tomcat服务器10.0.0.3上，使用的是8080端口。如果我们用5个并发来进行压测的话，创建的链接如下图所示

![img](E:\研究生学习\Work\技术笔记\计网常见问题.assets\2019082014083037.jpeg)

 

#### **链接发起端**

对于Jmeter来说，它是链接发起端，Jmeter创建了5个链接去连接服务端的8080端口，每个新建链接会占用了一个端口号，如图中的10001-10005。在操作系统中，端口号的范围是0-65535，其中0-1024是预留端口号，不可使用，其他的端口都是可以使用的。也就是说，**在链接发起端，受端口号的限制理论上最多可以创建64000左右链接。**

那么有没有办法超过这个限制呢，答案是肯定的！**通过网卡去绑定多个IP来设置**

通过TCP标识的四元组可以看到，对于链接发起端，影响链接数的是本地ip和port，端口号受限于65535，已经没办法增加了。那我们可以增加本地ip来达到这个目的。一般情况下，服务器的一个网卡上只绑定了一个ip，对外通信都使用这个ip进行。其实网卡是支持一个绑定多个IP的（必须确保ip是有效的且未使用的）

ifconfig eth0:1 10.0.0.5

以上命令可以在eth0网卡上增加一个ip 10.0.0.5，服务器网卡每增加一个ip，就可以允许在这个ip上再创建65535左右的链接数。

我曾经做过一个邮件网关的链接数测试，目的是为了测试网关服务器可以接收并且保持多少TCP长连接。正常情况下，受限于单台机器65535端口号的影响，客户端想创建25万TCP长连接，至少需要4台机器。通过对客户端网卡绑定多IP的方法，成功在一台机器上创建了25万个链接。

当然，这种手段只是一种非常规的操作，只是为了进行某种特殊场景的测试。正常情况下不推荐网卡绑定多个IP。

#### 链接接收端

对于Tomcat服务器来讲，它是链接接收端，它是不是也受限于65535呢？并不是，从上面图中可以看到，Jmeter发起的所有链接都创建在Tomcat服务器的8080端口，也就是说对于链接接收端，所有的链接占用的是同一个端口。根据TCP标识四元组可以分析出，**一个链接接收端，最大的TCP链接数=所有有效ip排列组合的数量\*端口数量64000**，这个计算结果应该是一个天文数字（我数学不好就不计算了，差不多相当于我一年的工资总和）。**因此链接接收端支持的链接数理论上可以认为是无限大的。**最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方

上面介绍的一些数据都是理论上单台机器可以支持的TCP链接数，**实际情况下，每创建一个链接需要消耗一定的内存，大概是4-10kb，所以链接数也受限于机器的总内存。(链接发起端,活力全开才64000左右链接，内存最多才占用640M，一般客户端都能满足；内存限制主要还是考虑服务器端)**