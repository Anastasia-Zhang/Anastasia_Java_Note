# 设计

Druid具有多进程，分布式架构，旨在实现云友好且易于操作。每种Druid进程类型都可以独立配置和扩展，从而为您的集群提供最大的灵活性。这种设计还提供了增强的容错能力：一个组件的故障不会立即影响其他组件。

### 进程和服务器

Druid主要有以下几种进程类型：

- **Coordinator** 进程管理群集上的数据可用性。
- **Overload**进程控制数据提取工作负载的分配。
- **Broker**进程处理来自外部客户端的查询。
- **Router**进程是可选进程，可以将请求路由到 Broke， Overlord 和 Coordinator。
- **Historical**进程存储可查询的数据。
- **MiddleManager**进程负责摄取数据。

Druid进程可以按照您喜欢的任何方式进行部署，但是为了易于部署，一般讲进程组织为三种服务器类型：主服务器，查询服务器和数据服务器。

* **主服务器（Master Service）**：运行 Coordinator 和 Overload 进程，管理数据可用性和接收。
* **查询服务器（Query Service）**：运行 Broker和 Router进程，处理来自外部客户端的查询。
* **数据服务器（Data Service）**：运行 Historical 和 MiddleManager 进程，执行提取工作负载并存储所有可查询的数据。

### 外部依赖

Druid还具有三个外部依赖项。利用外部依赖来实现数据的存储和集群的管理。

#### 深度存储（Deep Storage）

深度储存提供每个Druid服务器均可访问的共享文件存储。在集群部署中，深度存储通常将是分布式对象存储（例如 S3 或 HDFS）或网络安装的文件系统。而在单服务器部署中，这通常是本地磁盘。Druid使用深度存储来存储已经到系统中的所有数据。

**Druid仅将深度存储用作数据的备份，并作为在Druid进程之间在后台传输数据的方式**。在查询数据时并没有用到数据存储。响应查询时，Historical 进程会从其本地磁盘读取预提取的段。这也意味着在深度存储和历史进程中，必须有足够的磁盘空间用于计划加载的数据。

深度存储是Druid的弹性，容错设计的重要组成部分。即使每台数据服务器都丢失并重新配置，Druid也可以从深度存储中恢复数据。

#### 元数据存储（Metadata Storage）

元数据存储区包含各种共享的系统元数据，例如段使用信息和任务信息。在集群部署中，这通常将是传统的关系型数据库系统（RDBMS），例如 PostgreSQL 或 MySQL。在单服务器部署中，它通常将是本地存储的Apache Derby数据库。

#### Zookeeper

Zookeeper 主要用于管理集群的状态，包含以下场景

1. Coordinator 和 Overlord leader 的选举
2. 协议、Overload 和 MiddleManager 任务的管理

### 系统架构图

架构图下图显示了使用Master / Query / Data服务器组织的查询和数据在整个体系结构中的流动方式：![img](https://druid.apache.org/docs/latest/assets/druid-architecture.png)

### 存储设计

#### 数据源和段

Druid数据存储在“数据源”中，类似于传统RDBMS中的表。每个数据源都按时间分区，并且可以选择按其他属性进一步分区。每个时间范围都称为“块（chunk）”（例如，如果您的数据源按天划分，则为一天）。在一个块中，数据被划分为一个或多个 “段（segments）”。每个段都是单个文件，通常包含多达几百万行的数据。一个数据源可能来自于从几个段到数十万甚至数百万个段的任何位置。![img](https://druid.apache.org/docs/latest/assets/druid-timeline.png)每个段刚开始是在MiddleManager上创建的，并且那时是**可变的且未提交的**。段构建过程包括以下步骤，这样设计是为了生成紧凑且支持快速查询的数据文件：

* 转换为列格式
* 使用位图索引编制索引
* 使用各种算法进行压缩
  * 使用字典编码来完成字符串列ID的最小化存储
  * 位图索引使用位图压缩

分段会定期**提交和发布**，在这个时候，它们被写入深度存储，变得不可变，并从 MiddleManagers 迁移到Historical 进程。有关该段的相关信息也将写入到元数据存储中。这些相关信息包括段的模式、大小及和在深度存储上的位置之类的信息。这些相关信息帮助 Coordinator进程 了解集群上应该有哪些数据内容。

段的数据结构如下图：

![Druid column types](https://druid.apache.org/docs/latest/assets/druid-column-types.png)

它本质上是列式存储的：每个列的数据以单独的数据结构布局。通过单独存储每一列，德鲁依可以通过只扫描那些实际上需要查询的列来减少查询延迟。有三种基本列类型:时间戳列、维度列和度量列。

时间戳和度量列：每个列都是用LZ4压缩的整数或浮点值数组。一旦查询知道需要选择哪些行，它就会对这些行进行解压缩，提取出相关的行，并对想用的列进行聚合操作。与所有列一样，如果查询不需要列，则跳过该列的数据。

维度列是不同的，因为它们支持筛选和分组操作，所以每个维度需要以下三个数据结构来**提高查询速度**:

1. **字典**：将值(通常被视为字符串)映射为整数id，这样列表的值可以更加简洁和紧凑的存储
2. **列值的列表**，使用上述字典进行编码，这样主要用于 group by 和 topN的聚合操作
3. **位图编码：**对于列中的每个不同值，使用位图指示哪些行包含该值。使用位图索引，也成*反向索引*，允许快速过滤操作(具体来说，位图便于快速应用AND和OR操作符)

#### 索引和切换（handoff）

索引主要用于创建新段，切换主要用于段的发布和开始被 historical 进程使用。

索引端的工作方式如下：

1. 一个索引任务开始运行，建立一个新的段。在创建一个新段前并指定该段的标识符。对于要追加的任务（例如Kafka任务或追加模式中的索引任务），可以通过在Overlord进程上调用“分配” API来完成，来将新分区添加到现有的段的集和中。对于要覆盖的任务（例如Hadoop任务或不在附加模式下的索引任务），这可以通过锁定间隔并创建新的版本号和新的段集来完成。
2. 如果索引任务是实时任务（例如Kafka任务），则此时可以立即查询该段。它可用，但尚未发布。
3. 索引任务完成对段的数据读取后，将其写入深度存储，然后通过将记录写入元数据存储来发布它。
4. 如果索引任务是实时任务，则此时它等待“历史”进程加载该段。如果索引任务不是实时任务，它将立即退出。

在Coordinator/Historical方面这样：

1. Coordinator 定期（默认情况下，每1分钟）轮询元数据存储区以查找新发布的段。
2. 当协调器找到已发布和使用但不可用的段时，它会选择一个“Historical”进程来加载该段并指示“历史记录”这样做。
3. 历史进程会加载该段并为其服务。此时，如果索引任务正在等待切换，它将退出。

#### 段标识符

段标识符段具有包含以下部分组成：

* 数据源名称

* 时间间隔（对于包含分段的时间块；这对应`segmentGranularity`于写入时指定的时间间隔）

* 版本号（通常为ISO8601时间戳，与首次启动段集的时间相对应）

* 分区号（整数，在数据源 + 间隔 + 版本内是唯一的；可能不一定是连续的）

  如以下标识符：数据源： `clarity-cloud0`，时间块 `2018-05-21T16:00:00.000Z/2018-05-21T17:00:00.000Z`，版本号：`2018-05-21T15:56:09.909Z` 和分区号1

  ```
  clarity-cloud0_2018-05-21T16:00:00.000Z_2018-05-21T17:00:00.000Z_2018-05-21T15:56:09.909Z_1 
  ```

  分区号为0（块中的第一个分区）的段省略了分区号。

#### 段版本控制

版本号支持批处理模式覆盖。在Druid中，如果只是追加数据，那么每个块只有一个版本。但是，当覆盖数据时，其实是使用相同的数据源，相同的时间间隔，但版本号更高的方式创建了一组新的段。然后向Druid系统的其余部分发出信号，告诉他们应从群集中删除较旧的版本，而应使用新版本替换它。

替换是对于用户而言是瞬间发生的。Druid首先加载新数据（但不允许对其进行查询），当所有新数据加载完毕后，立即切换所有新查询来使用这些新的数据。在几分钟之后删除了旧的段。

#### 段的生命周期

在以下三个领域每个段都有一个生命周期：

1. **元数据存储区：**一旦构建完段，就将段元数据（小的JSON有效负载，通常不超过几个KB）存储在元数据存储区中。**将段的记录插入元数据存储的操作称为发布**。这些元数据记录具有一个名为的布尔标志`used`，该标志控制该段是否可查询。由实时任务创建的段在发布之前是可用的，因为它们仅在段完成时才发布，并且不接受任何其他数据行。
2. **深度存储：**段数据构建完成后，会将分段数据文件推送到深度存储。这在将元数据发布到元数据存储之前立即发生。
3. **查询的可用性：**段可用于在某些Druid数据服务器上进行查询。

可以使用Druid SQL `sys.segments`表检查当前活动段的状态 。它包括以下标志：

* `is_published`：如果分段元数据已发布到元数据存储中，`used`则为true
* `is_available`：如果该段当前可用于实时任务或Historical进程查询，则为True。
* `is_realtime`：如果段仅在实时任务上可用，则为true 。对于使用实时提取的数据源，通常会先开始`true`，段的发布和移交完成之后自动变为`false`
* `is_overshadowed`：如果该段已发布（`used`设置为true）并且被其他一些已发布的段完全遮盖，则为true。通常，这是一个过渡状态，处于此状态的段很快就会将其`used`标志自动设置为false。

### 查询过程

查询处理查询首先进入Broker，Broker将在其中识别哪些段具有与该查询有关的数据。段列表始终按时间剪枝（prune），也可以根据其他属性来剪枝，这取决于数据源的分区方式。

然后，Broker将确定哪些 Historical 和 MiddleManager 正在为这些段提供服务，并将重写的子查询发送给每个流程。

Historical / MiddleManager进程将接受查询，对其进行处理并返回结果。Broker接收结果并将结果合并在一起以得到最终结果并返回。

Broker剪枝是Druid限制每个查询必须扫描的数据量的一种重要方法，但这不是唯一的方法。对于比Broker用于剪枝更细粒度级别的过滤器，在查看每个数据之之前，每个段内的索引结构允许Druid在查看哪些行(如果有的话)匹配这些过滤器集。

一旦Druid知道哪些行与特定查询匹配，它就只会访问该查询所需的特定列。在这些列中，Druid可以在行与行之间跳过，从而避免读取与查询过滤器不匹配的数据。因此，Druid使用三种不同的技术来最大化查询性能：

* 对每个查询的段进行剪枝
* 在每个段中，使用索引来标识必须访问的行
* 在每个段中，仅读取与特定查询相关的特定行和列。